{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa95dac7-6b2d-4298-887a-2e24b47acafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gains:\n",
      "age: 0.24674981977443933\n",
      "income: 0.02922256565895487\n",
      "student: 0.15183550136234159\n",
      "credit_rating: 0.04812703040826949\n",
      "\n",
      "Root Node (Highest Information Gain): age\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Create a DataFrame with the provided data\n",
    "\n",
    "data = [\n",
    "    [\"<=30\",\"high\", \"no\", \"fair\", \"no\"],\n",
    "    [\"<=30\",\"high\", \"no\", \"excellent\",  \"no\"],\n",
    "    [ \"31â€¦40\",\"high\", \"no\", \"fair\", \"yes\"],\n",
    "    [ \">40\",\"medium\", \"no\", \"fair\", \"yes\"],\n",
    "    [\">40\",\"low\", \"yes\", \"fair\",  \"yes\"],\n",
    "    [ \">40\",\"low\", \"yes\", \"excellent\", \"no\"],\n",
    "    [ \"30...40\", \"low\", \"yes\", \"excellent\",\"yes\"],\n",
    "    [ \"<=30\", \"medium\", \"no\", \"fair\",\"no\"],\n",
    "    [\"<=30\", \"low\", \"yes\", \"fair\", \"yes\"],\n",
    "    [\">40\", \"medium\", \"yes\", \"fair\", \"yes\"],\n",
    "    [\"<=30\", \"medium\", \"yes\", \"excellent\", \"yes\"],\n",
    "    [\"31...40\", \"medium\", \"no\",\"excellent\", \"yes\"],\n",
    "    [\"31...40\", \"high\", \"yes\",\"fair\", \"yes\"],\n",
    "    [\">40\", \"medium\", \"no\", \"excellent\", \"no\"],\n",
    "]\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"age\", \"income\", \"student\", \"credit_rating\", \"buys_computer\"])\n",
    "\n",
    "\n",
    "# Calculate the entropy of the class label 'buys_computer'\n",
    "def calculate_entropy(data):\n",
    "    total_samples = len(data)\n",
    "    if total_samples == 0:\n",
    "        return 0\n",
    "    positive_samples = sum(data['buys_computer'] == 'yes')\n",
    "    negative_samples = sum(data['buys_computer'] == 'no')\n",
    "    p_positive = positive_samples / total_samples\n",
    "    p_negative = negative_samples / total_samples\n",
    "    if p_positive == 0 or p_negative == 0:\n",
    "        return 0\n",
    "    entropy = -p_positive * math.log2(p_positive) - p_negative * math.log2(p_negative)\n",
    "    return entropy\n",
    "\n",
    "entropy_root = calculate_entropy(df)\n",
    "\n",
    "# Calculate Information Gain for each attribute\n",
    "def calculate_information_gain(data, attribute, root_entropy):\n",
    "    unique_values = data[attribute].unique()\n",
    "    weighted_entropy_after_split = 0\n",
    "    for value in unique_values:\n",
    "        subset = data[data[attribute] == value]\n",
    "        subset_entropy = calculate_entropy(subset)\n",
    "        weight = len(subset) / len(data)\n",
    "        weighted_entropy_after_split += weight * subset_entropy\n",
    "    information_gain = root_entropy - weighted_entropy_after_split\n",
    "    return information_gain\n",
    "\n",
    "# Calculate Information Gain for each attribute\n",
    "root_entropy = calculate_entropy(df)\n",
    "information_gains = {}\n",
    "for attribute in df.columns[:-1]:  # Exclude the 'buys_computer' column\n",
    "    information_gain = calculate_information_gain(df, attribute, root_entropy)\n",
    "    information_gains[attribute] = information_gain\n",
    "\n",
    "# Identify the attribute with the highest Information Gain as the root node\n",
    "root_node = max(information_gains, key=information_gains.get)\n",
    "\n",
    "print(\"Information Gains:\")\n",
    "for attribute, gain in information_gains.items():\n",
    "    print(f\"{attribute}: {gain}\")\n",
    "\n",
    "print(f\"\\nRoot Node (Highest Information Gain): {root_node}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f48649c-9504-4573-824b-745f7296f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Depth: 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load your dataset (replace 'data.csv' with your data file)\n",
    "\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop(columns=['buys_computer'])\n",
    "y = df['buys_computer']\n",
    "\n",
    "# Handle categorical variables (one-hot encoding)\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Impute missing values (if any)\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "X_imputed = imputer.fit_transform(X_encoded)\n",
    "\n",
    "# Combine the encoded and imputed data with non-categorical columns\n",
    "X_final = pd.concat([pd.DataFrame(X_imputed), X.drop(columns=categorical_cols)], axis=1)\n",
    "\n",
    "# Create and fit the Decision Tree model\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_final, y)\n",
    "\n",
    "# Get the depth of the constructed tree\n",
    "tree_depth = model.get_depth()\n",
    "\n",
    "print(f\"Decision Tree Depth: {tree_depth}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
